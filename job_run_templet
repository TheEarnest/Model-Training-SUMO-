#!/bin/bash
###############################################################################
#                              JobName.run
#   Automatically generated by Create_TASKS.frm using the m4 macro processor.
###############################################################################
#
#   R U N - Script for the model configuration cosmos-ao
#
#   COSMOS-AO is a coupled model configuration with the components
#      ECHAM5 - global atmosphere GCM (MPI-HH)
#      MPIOM  - global ocean GCM (MPI-HH)
#
###############################################################################
#### Batch Queuing System is PBS pro
#PBS -A nn9039k
#PBS -N r_JobName
#PBS -q batch
#PBS -l mppwidth=128
#PBS -l walltime=00:59:00
#PBS -j oe
#PBS -S /bin/bash
###############################################################################
#------------------------------------------------------------------------------
#
#     0. PROLOGUE
#
#------------------------------------------------------------------------------
set -e
export task=RUN     # The task: RUN, ARCH, POST, VIS, MON, REM
echo "\n This ${task} script\n - is started at\t$(date)\n - running on host\t$(hostname)"

module load mpt


###############################################################################
#
#        SETUP OF EXPERIMENT JobName
#
###############################################################################
#------------------------------------------------------------------------------
#   0.1   Experiment settings
#------------------------------------------------------------------------------

#
#-- Experiment ID
#

export expid=JobName

#
#-- Coupled model name
#

export cplmod=cosmos-ao

#
#-- Node name of the computing host
#

export node=crayx1

#------------------------------------------------------------------------------
# Setup of COSMOS-AO
#------------------------------------------------------------------------------
#-- Component model names
#
atmmod=echam5
# MLS used for multi AGCM ----------------------------------------------
atmmonprefix="echA"
atmids="01 02 "
#UsingAreaWeight=".TRUE."
UsingAreaWeight=".FALSE."
mcoefs="-5 "
# fields are   
#        " 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15" for AGCM 1
#mFDcoefs=" #mMoCoef, #mMoCoef, #mMoCoef, #mMoCoef, #mMoCoef, #mMoCoef, #mMoCoef, #mMoCoef, #mMaCoef, #mMaCoef, #mMeCoef, #mMeCoef, #mMeCoef, #mMeCoef, #mMoCoef"
EWma=#mMaCoef
EWmo=#mMoCoef
EWht=#mMeCoef
mFDcoefs=" ${EWmo}, ${EWmo}, ${EWmo}, ${EWmo}, ${EWmo}, ${EWmo}, ${EWmo}, ${EWmo}"
mFDcoefs=${mFDcoefs}", ${EWma}, ${EWma}"
mFDcoefs=${mFDcoefs}", ${EWht}, ${EWht}, ${EWht}, ${EWht}, ${EWmo}"
# flux physical id 
# 1: mass; 2: momuntum; 3: energy
EIDma=1;EIDmo=2; EIDht=3;
modFDgids=" ${EIDmo}, ${EIDmo}, ${EIDmo}, ${EIDmo}, ${EIDmo}, ${EIDmo}, ${EIDmo}, ${EIDmo}"
modFDgids=${modFDgids}", ${EIDma}, ${EIDma}"
modFDgids=${modFDgids}", ${EIDht}, ${EIDht}, ${EIDht}, ${EIDht}, ${EIDmo}"
# Treating methods are 
# 0: ensemble weight
# 1: sampling
ETma=0;ETmo=0; ETht=0;
mFDEmethods=" ${ETmo}, ${ETmo}, ${ETmo}, ${ETmo}, ${ETmo}, ${ETmo}, ${ETmo}, ${ETmo}"
mFDEmethods=${mFDEmethods}", ${ETma}, ${ETma}"
mFDEmethods=${mFDEmethods}", ${ETht}, ${ETht}, ${ETht}, ${ETht}, ${ETmo}"

# coupling fields 
# 01  surface_downward_eastward_stress_where_open_sea_U
# 02  surface_downward_eastward_stress_where_open_sea_V
# 03  surface_downward_northward_stress_where_open_sea_U
# 04  surface_downward_northward_stress_where_open_sea_V
# 05  surface_downward_eastward_stress_where_sea_ice_U
# 06  surface_downward_eastward_stress_where_sea_ice_V
# 07  surface_downward_northward_stress_where_sea_ice_U
# 08  surface_downward_northward_stress_where_sea_ice_V
# 09  lwe_surface_downward_snow_flux_where_sea_ice
# 10  water_flux_into_ocean
# 11  Residual_heat_flux
# 12  downward_heat_flux_in_sea_ice
# 13  surface_downward_heat_flux_in_air
# 14  surface_net_downward_shortwave_flux
# 15  wind_speed_at_10m
# ----------------------------------------------------------------------
ocemod=mpiom
coupler=oasis3

components="echam5 mpiom"

###############################################################################
#
#     1. USER INTERFACE
#
###############################################################################
#
#-- ECHAM5
#
res_atm=T31          # horiozontal grid resolution
                     #       T21  / T31  / T42 / T63 / T85 / T106 / T159
vres_atm=19          # number of vertical levels
                     #       19   / 19   / 19  / 31  / 31  / 31   / 31
atmvers=N02          # atmosphere model version (used in executable name)
out_filetype=GRIB    # output file format:  GRIB / NETCDF
arch_format=RAW      # archive file format: RAW / GRIB_SZIP
dt_write_atm=24       # time interval of output writing in hours
lhd=yes              # hydrological discharge model activated
millennium_ctrl=true # use namelist parameters for permanent year 800 (RADCTL)
volc_forc=false      # true: volcanic forcing: provide volc_data and rad_table
save_dblrad=false    # true: handle instantanous flux anomalies (accuflx) 

#
#-- MPIOM
#
res_oce=GR30         # horiozontal grid resolution (acronym)
                     #      GR30   /  GR15
vres_oce=40          # number of vertical levels
                     #      20/40  /   40
Temperture_Restoring_Time=6.
IsRestoringSST=no
if [ ${IsRestoringSST} = 'yes' ]; then
  ocevers=R01          # ocean model version (used in executable name)
                       # N01 -- Normal case;  R01 -- SST restoring case
else
  ocevers=N04
fi
#
#-- COUPLER
#
jobname=JobName          # OASIS experiment-id (3 characters)
nlogprt=0             # Standard output extent:
                     #    0: little
                     #    1: much
                     #    2: very much std. output
ncplvers=""          # namcouple version
                     #   "" for the default namcouple
                     #   for usage of an altenative namcoule: place it in 
                     #     prism/util/running/adjunct_files/oasis3 
                     #   and append the namcouple version to its name:
                     #     namcouple_'cplmod''ncplvers'
run_mode=concurrent  # sequential / concurrent (=parallel)

# remapping parameters

scripwr=0      # writing of SCRIP remapping matrices
               #   0: use SCRIP matrice if existing; else (re)calculation
               #   1: unconditional (re)calculation of SCRIP matrices

gridswr=0      # writing of grid description files for OASIS   
               #   0: use grid descript. files if existing; else (re)generation
               #   1: unconditional (re)generation of grid description files

extrapwr=1     # writing of extrapolation matrix (NINENN)
               #   0: use of existing extrapolation matrix (error if not 
               #      available)
               #   1: unconditional (re)generation of the extrapolation matrix
               #  Note: if gridswr=1 extrapwr needs to be 1 too

# time interval of data exchange

dto2a=86400    # coupling time step from ocean to atmosphere (86400/43200) [s]
               # Note: coupling time step from atmosphere to ocean is 86400 s

# treatment of coupling fields (see OASIS documentation for more information)

timtranso2a=AVERAGE   # INSTANT / AVERAGE
export=EXPORTED       # EXPORTED / EXPOUT

#------------------------------------------------------------------------------
#   1.2 TASK SPECIFICATION
#------------------------------------------------------------------------------
#
#-- preprocessing:   yes: create and run a script for preprocessing
#                    no:  no preprocessing
preprocessing=no

#
#-- postprocessing:  yes: create and run a script for postprocessing
#                    no: no postprocessing
postprocessing=yes

#
#-- splitting:       yes: split multi code output in codes (only possible, if postprocessing=yes)
#                    no: no splitting of codes
splitting=no

#
#-- dbfill:          yes: fill database according code lists (only possible, if postprocessing=yes and splitting=yes)
#                    no: no data base filling
dbfill=no
 
#-- monitoring :     yes:  create and run a script for monitoring
#                    no:   no monitoring
#
monitoring=no

#
#-- archiving:       yes: create and run a script for archiving
#                    no:  no archiving
archiving=no

#------------------------------------------------------------------------------
#   1.3 TIME CONTROL
#------------------------------------------------------------------------------
#-- declarations
#integer nyear nmonth nday nhour nminute nsecond

#
#-- calendar type: Available calendar options:
#     0   : No leap year (365 days per year)
#     1   : Gregorian (365/366 days per year)
#     n   : Equal months of "n" days (30 for 30 day months)

caltype=1

#
#-- initial and final date of the experiment
#   Format: YearMMDD[_hh[mm[ss]]], Year-MM-DD[_hh[:mm[:ss]]] or 
#           Year-MM-DD[Thh[:mm[:ss]]]
#   Note: The experiment will not stop within a run/chunk even if the
#         final date is reached.

initial_date=0800-01-01 # initial date of the experiment
final_date=1141-12-31   # final date of the experiment

#
#-- duration of a run/chunk
#      Specify the length of each run in one of the below units.

nyear=1          # number of years per run
nmonth=0         # number of months per run
nday=0           # number of days per run
nhour=0          # number of hours per run
nminute=0        # number of minutes per run
nsecond=0        # number of seconds per run
nstep_atm=0      # number of atmosphere model time steps per run
nstep_oce=0      # number of ocean model time steps per run


#------------------------------------------------------------------------------
#   1.4 INITIAL SETTINGS
#------------------------------------------------------------------------------
#
#--  use_initial_tarfile  - Get initial data from a tar file 
#         yes:   get initial data tar file from 'archive_in'
#          no:   all initial data is in place (short term archive 'data')

use_initial_tarfile=no

#
#-- tag to distinguish between different input data files
#

tag=""

#
#-- file and directory permissons of the output
#

export dir_permits=755
export file_permits=644

#--  fill_archive_in  - Store data from the tarfile as single files in
#                'archive_in'. This allows for usage with different experiments
#                (only with use_initial_tarfile=yes)
#         yes:   the data shall be stored as single files in 'archive_in'
#          no:   'archive_in' is not used 

fill_archive_in=no
suppress_links=yes

#------------------------------------------------------------------------------
#   1.5 MESSAGE PASSING
#------------------------------------------------------------------------------
#
#-- number of MPI-processors/openMP-threads
#

#integer nproca_atm nprocb_atm nproma_atm nthreadatm nproca_oce nprocb_oce nthreadoce
#integer nprocoasis

#20, Natm: 121;  Noce: 77; fNatm: 11  11; fNoce: 7  11
#5, 60, 39
nproca_atm=8   # 
nprocb_atm=4   # total number of MPI processors for the atmosphere is nproca_atm * nprocb_atm
nproma_atm=72  # vector length (see http://svn.zmaw.de/echam5/decomposition-sx.html)
nthreadatm=1   # number of openMP threads for the atmosphere model

nproca_oce=4   # 
nprocb_oce=8  # total number of MPI processors for the ocean is nproca_oce * nprocb_oce
nthreadoce=1   # number of openMP threads for the ocean model

nprocoasis=1   # number of processors dedicated for OASIS (1/0)

#########################################################################
#

message_passing=MPI1

#
#-- buffered MPI Send 
#      yes: buffered send
#       no: simple send

bsend=no

#
#-- number of processors used for the mpiexec
# 

nprocmpi=0

#------------------------------------------------------------------------------
#   1.6 FILE SYSTEMS
#------------------------------------------------------------------------------
#
#-- home:  Permanent file system for the SCRIPTS on the COMPUTING HOST
#          (only needs to be specified if the tasks are NOT generated on the 
#          computing host)

set -ex
export home=#HOMEDIR

#
#-- archive_in:  Root directory of the LONG TERM INPUT data archive. It needs
#                to reside on the same machine as the output archive. This 
#                archive is intended for input data that is needed with 
#                several experiments, e.g. initial , forcing or restart files.
#
#  - The parent-directory of ${archive_in} needs to exist before submission of the job- 

export archive_in=#WORKDIR

#
#-- data:  Root directory of the SHORT TERM data server.
#          Model INPUT and OUTPUT will be read from/written to 
#          this file system of the computing host
#
#  - The parent-directory of ${data} needs to exist before submission of the job 

export data=#WORKDIR

#
#-- archive:  Root directory of the LONG TERM OUTPUT data archive.
#             - Either a filesystem of the computing host or of a remote archiving host. 
#             If ${archive} differs from ${data} model output will be saved in 
#             ${archive} and removed from ${data}.
#
#  - The parent-directory of ${archive} needs to exist - 

export archive=#WORKDIR

#
#-- work:  Root directory for the temporary working directory
#             (for production runs use $TMPDIR on NEC)
#

work=#WORKDIR

#
#-- Compilation
#
#       compile_server: Node name of the compile-server
#         compile_path: Directory where the executables are stored
#                       on the compile-server

compile_server=crayx1
compile_path=/home/uib/earnest/models/COSMOS/Ccosmos/crayx1/bin

#
#-- Path to the IMDI function directory
#
export fpath=/home/uib/earnest/models/COSMOS/Ccosmos/util/running/functions
export PATH=${fpath}:$PATH
#------------------------------------------------------------------------------
#   1.7 RESTART CONTROL
#------------------------------------------------------------------------------ 
#
#-- 'component'_restart: start from restart or initial files (climatology)
#         1  : start experiment from restart files for 'component'
#         0  : start experiment from initial conditions for 'component'
#      If the experiment starts from restart files you need to specify:
# 
#   'component'_age: the age of the restart file used in years
#   'component'_restart_file: filename of the restart file (including path)
#

atm_restart=1
atm_age=0
atm_restart_file=${data}/${expid}/restart/echam5/rerun_echam.nc
atm_restart_accu=${data}/${expid}/restart/echam5/rerun_accuflx.nc
hd_restart_file=${data}/${expid}/restart/echam5/hdrestart.nc

oce_restart=1
oce_age=0
oce_restart_file=${data}/${expid}/restart/mpiom/rerun_mpiom.ext

cpl_restart=1
cpl_restart_file_sstocean=${data}/${expid}/restart/oasis3/sstocean.nc
cpl_restart_file_flxatmos=${data}/${expid}/restart/oasis3/flxatmos.nc

#------------------------------------------------------------------------------
#   1.8 PLATFORM DEPENDEND SPECIFICATIONS
#------------------------------------------------------------------------------
# 
#-- set system stuff required:
#

if [ "$(uname -m)" = "crayx1e" ] || [ "$(uname -m)" = "crayx1" ]; then

  if [ -f /opt/modules/modules/init/ksh ]; then
    . /opt/modules/modules/init/ksh
    module load pbs PrgEnv.56 open-pack met-pack
  else
    echo "ERROR: module command not available."
    exit 1
  fi

#
#-- batch queueing system ( PBS | PBSpro | SGE | LL | NQS2 | LSF )
#
queueing_system=PBSpro

#
#-- email address (for queuing system)
#
email=earnestshen@gmail.com

#
#-- account (for queuing system)
#
account=default       # KMA account number ("default" for default account) 

#
#-- queue (for queuing system)
#
queue=normal         # queue name ("default" for default queue) 

#
#--  Set size of output buffer:
#
  export FILENV=${work}/${expid}/work/.assign

  assign -R

  assign -Y on f:OCECTL
  assign -Y on f:namelist.echam
  
  assign -D stderr u:0

  assign -b 1 u:6
  assign -b 1 u:7
  assign -b 1 u:8

# for all others the default is 4096

fi
#------------------------------------------------------------------------------
#   1.9 UNIX COMMANDS
#------------------------------------------------------------------------------

export mkdir="mkdir -p"  # create a new directory
export cp="cp -p"        # copy without changing the time stamp
export ln="ln -sf"       # soft link (if no links are wanted: same as cp)
export rm=rm             # remove
export rtp=ftp           # remote transfer protocol
export rtp_post=$rtp     # transfer protocol to remote processing host
export put_archive=""    # special command to put files to band archive (e.g. dsmc)
export get_archive=""    # special command to get files from band archive (e.g. dsmc)
export gunzip="gzip -d"  # unzip a file that was zipped using gzip
export job_account=""    # command to receive job account at the end of the run

module load cdo
export cdo=cdo    # climate data operator
export python=/sw/sdev/Modules/python/python-2.7.2/bin/python   # python

#------------------------------------------------------------------------------
#   1.10 REMOTE DATA PROCESSING
#------------------------------------------------------------------------------

#
#-- Perform data processing on remote host: yes/no
#
postprocessing_rem=no              # yes/no
monitoring_rem=no                  # yes/no
dbfill_rem=no                      # yes/no
archiving_rem=no                   # yes/no

#
#-- data_rem:  Location, where data processing (postprocessing etc.) should be performed.
#        It is specified as [processing_host:][processing_path], e.g.
#
#        data_rem=$data                  default, i.e processing in the directory 
#                                        ($data) on the compute (frontend) host
#        data_rem=mil00.zmaw.de:/mil00   TPP: processing on host mil00.zmaw.de 
#                                              in the working directory /mil00
data_rem=$data
[[ $(echo ${data_rem} | grep :) = "" ]] && host_rem="" || host_rem=${data_rem%%:*}
path_rem=${data_rem#*:}

#
#-- qsub_rem:  Submit command for the processing jobs on remote host
#
#              qsub_rem=$qsub                     default, i.e. processing jobs are submitted
#                                                 with the same command as the run job ($qsub)
#              qsub_rem=sge_qsub                  TPP
#              qsub_rem='ssh [-l user] nohup'     processing on remote host without 
#                                                 queueing system (interactive) 
qsub=qsub
qsub_rem=$qsub
qsub_rem_sync=$qsub_rem' -sync y'                 # wait for the job to complete before exiting

#
#-- Path to the IMDI function directory on remote processing host
#
fpath_rem=${path_rem}/${expid}/functions
[[ "${fpath}" = "${fpath_rem}" ]] || export PATH=$PATH:${fpath_rem}

#
#-- Submit host (i.e. compute or frontend node)
#
submit_host=vilje

#
#-- chron_proc:  Data processing in chronological order: yes/no
#
chron_proc=yes

###############################################################################
#
#      END OF THE USER INTERFACE
#
###############################################################################

set -e
#------------------------------------------------------------------------------
#
#  Complete setup of COSMOS-AO (parameters wich cannot be changed)
#
#------------------------------------------------------------------------------
#
# declarations
#
#integer ntproc nprocatm nprococe nprocmpi ncplprococe ncplprocatm

#
# treatment of coupling fields
#
timtransa2o=INSTANT

#
# Exchange time steps
#
dta2o=86400
dto2a=${dto2a}

# Parameters for ECHAM5
# ---------------------
#
#-- Time step
#
if [ ${vres_atm} = 19 ]; then
  if [ ${res_atm} = T21 ]; then
    nadt=2400
  elif [ ${res_atm} = T31  ]; then 
    nadt=2400
  elif [ ${res_atm} = T42  ]; then
    nadt=1800
  elif [ ${res_atm} = T63  ]; then
    nadt=1200
  elif [ ${res_atm} = T85  ]; then
    nadt=900
  elif [ ${res_atm} = T106 ]; then
    nadt=720
  fi
elif [ ${vres_atm} = 31 ]; then
  if [ ${res_atm} = T31  ]; then 
    nadt=1800
  elif [ ${res_atm} = T42  ]; then
    nadt=1200
  elif [ ${res_atm} = T63  ]; then
    nadt=720
  elif [ ${res_atm} = T85  ]; then
    nadt=480
  elif [ ${res_atm} = T106 ]; then
    nadt=360
  elif [ ${res_atm} = T159 ]; then
    nadt=240
  fi
fi

# Parameters for MPIOM
# --------------------
#
#-- Time step and grid dimensions
#
if [ ${res_oce} = GR30 ]; then
  nx_oce=122
  ny_oce=101
  nodt=8640
elif  [ ${res_oce} = GR15 ]; then
  nx_oce=256
  ny_oce=220
  nodt=4320
elif  [ ${res_oce} = T43 ]; then
  nx_oce=130
  ny_oce=211
  nodt=4800
  echo " TIMESTEP NEEDS TO BE CHECKED!"
fi

#
# Number of MPI-processors/openMP-threads
# ---------------------------------------
ncplprococe=1  # number of ocean MPI processes communicating with oasis
ncplprocatm=1  # number of atmosphere MPI processes communicating with oasis

(( nprocatm=nproca_atm*nprocb_atm ))  # total number of atm. MPI processes
(( nprococe=nproca_oce*nprocb_oce ))  # total number of ocean MPI processes

# total number of MPI processes
(( ntproc=nprocatm+nprococe+nprocmpi+nprocoasis ))

export OMP_NUM_THREADS=1
export MPIOM_THREADS=${nthreadoce}
export ECHAM5_THREADS=${nthreadatm}

#------------------------------------------------------------------------------
#
#   Directory and name of this script
#
#------------------------------------------------------------------------------

if [ "${qsub}" = "qsub" ]; then
  jobdir=${home}/${expid}/scripts       # directory of this script
  #jobid=$PBS_JOBID                      # job-id
  #job=$PBS_JOBNAME                      # name of this script
  cd ${jobdir}
  #jobdir=`pwd`
  jobid=${expid}
#  job=`basename $0`
  job=${expid}.run
else
  jobdir=`dirname $0`
  cd ${jobdir}
  jobdir=`pwd`
  jobid=${expid}
  job=`basename $0`
fi
echo ${jobdir}
#------------------------------------------------------------------------------
#
#     3. CALENDAR
#
#------------------------------------------------------------------------------
#
#-- calculate length of the run in seconds for the case that (optionally)
#   the length of run is given in number of model steps of any of the models.
#
nstep_che=0
nstep_srf=0
if   [ "${nstep_atm}" -ne 0 ] && [ "${nstep_atm}" -ne "" ]; then
  (( nsecond = nstep_atm * nadt ))
elif [ "${nstep_oce}" -ne 0 ] && [ "${nstep_oce}" -ne "" ]; then
  (( nsecond = nstep_oce * nodt ))
elif [ "${nstep_che}" -ne 0 ] && [ "${nstep_che}" -ne "" ]; then
  (( nsecond = nstep_che * ncdt ))
elif [ "${nstep_srf}" -ne 0 ] && [ "${nstep_srf}" -ne "" ]; then
  (( nsecond = nstep_srf * nsdt ))
fi

#
#-- find out smallest time unit in inidate and job length
#
inidate=`format_date -- ${initial_date}`   # transform to format (YearMMDD_hhmmss)
findate=`format_date -- ${final_date}`

nwords=$(format_date -f4 -- ${inidate} | wc -w) 
if [ ${nwords} -eq 6 ] || [ ${nsecond} -ne 0 ]; then
  inidate=$(format_date -s -- ${inidate})
  findate=$(format_date -s -- ${final_date})
elif [ ${nwords} -eq 5 ] || [ ${nminute} -ne 0 ]; then
  inidate=$(format_date -m -- ${inidate})
  findate=$(format_date -m -- ${final_date})
elif [ ${nwords} -eq 4 ] || [ ${nhour} -ne 0 ]; then
  inidate=$(format_date -h  -- ${inidate})
  findate=$(format_date -h  -- ${final_date})
fi

#
#-- date of this run
#

cd ${jobdir}
space_error="no"

datefmt='%a %b %d %H:%M:%S %Z %Y'  # date format for expid.log file

if [ ! -f ${expid}.date ]; then

  startdate=${inidate}
  jobnum=1
  if [ -f  ${expid}.log ]; then
    rm ${expid}.log
  fi
  echo "$(date +"${datefmt}") :  Beginning of Experiment ${expid}" > ${expid}.log.new || { 
      space_error="yes"; echo "Could not create ${expid}.log"; 
  }
else
  read startdate jobnum < ${expid}.date
  cp ${expid}.log ${expid}.log.new || { 
    space_error="yes"; echo "Could not save ${expid}.log"; 
  }
fi

echo "$(date +"${datefmt}") :  ${jobnum} ${startdate} ${jobid}  - start" >> ${expid}.log.new || { 
  space_error="yes"; echo "Could not append to ${expid}.log"; 
}
if [ "${space_error}" = "no" ]; then
  mv ${expid}.log.new ${expid}.log
else
  echo "  |- ERROR: No disk space left or quota exceeded?"
  exit 1
fi

#integer scrcap
line=$(df -k $data | tail -1)
scrfs=${line##* }
line=${line%%\%*} ;scrcap=${line##* }

if (( scrcap > 99 )); then
  echo "  |- ERROR: Less than 1% disc space left on filesystem $scrfs, where your"
  echo "  |    workshare data=$data is mounted. Please clean up before you continue !"
  exit 1
fi

nextdate=$(calc_date plus -c${caltype} -Y${nyear} -M${nmonth} -D${nday} -h${nhour} -m${nminute} -s${nsecond} -- ${startdate})

echo " |+ Time integration and run periode"
echo "  |- Initial date of the experiment:\t${inidate}"
echo  "  |- Final date of the experiment:\t${findate}"
echo "   |- Beginning of this run    :\t${startdate}"
echo "   |- Beginning of the next run:\t${nextdate}\n"

#------------------------------------------------------------------------------
#
#   Definition of the functions 
#
#------------------------------------------------------------------------------

. function_check_size
. function_check_codes
. function_dbfill
. function_generate_tarfile
. function_get_file
. function_get_model_resolution
. function_get_tarfile
. function_make_directories
. function_make_ppdirectories
. function_prepare_saving
. function_put_file
. function_plot_file
. function_pperror

#------------------------------------------------------------------------------
#
#    4. PRE PROCESSING
#
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
#   4.1 DIRECTORY DEFINITION
#------------------------------------------------------------------------------

if [ "$(hostname)" = "${host_rem%%.*}" ] ; then 
   exphome=${path_rem}/${expid}   # Root directory of the experiment (data)
else
   exphome=${data}/${expid}       # Root directory of the experiment (data)
fi
export bindir=${exphome}/bin      # Directory of the executables
export inpdir=${exphome}/input    # Directory of the input files
export restdir=${exphome}/restart # Directory of the restart files
export outdir=${exphome}/outdata  # Directory of the output data files
export logdir=${exphome}/log      # Directory of the log data files
export postdir=${exphome}/post    # Directory for postprocessed data

if [ ${jobnum} = 1 ];then
   if [ "${task}" = "RUN" ]; then
      make_directories
   elif [ "${task}" = "REM" ]; then
      make_ppdirectories
   fi
fi

#------------------------------------------------------------------------------
#
#     save log file of the previous run
#
#------------------------------------------------------------------------------
#
# find out the id of the last run
#
if [ ${jobnum} != 1 ]; then
  previd=` grep -- ${startdate} ${expid}.log | grep done | cut -d: -f5 | cut -d. -f1`
  if [ "${previd}" = "" ]; then
    previd=` grep -- ${startdate} ${expid}.log | grep ${expid}`
    if [ "${previd}" != "" ]; then 
      echo "No logfile of the previous run available (interactive run)"
    else
      echo "WARNING: No logfile of the previous run available!"
    fi
  else
    logfile=${job}.o${previd}
    date=` grep ":${previd}\." ${expid}.log | grep start | tr -s " " | cut -d" " -f9 | uniq`
    if [ ! -f ${jobdir}/${logfile} ] \
       && [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
      sleep 300
      echo "waiting for the log file of the previous run: ${logfile} ..."
    fi
    if [ -f ${jobdir}/${logfile} ]; then
      mv ${jobdir}/${logfile} ${logdir}/${job}_${date}.o${previd}
    elif [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
      echo "No logfile of the previous run - exit"
      exit
    fi
  fi
fi
#------------------------------------------------------------------------------
#   4.3 PRE - PROCESSING : Get the input data tar-file
#------------------------------------------------------------------------------

if [ ${jobnum} = 1 ]; then
  get_tarfile ${use_initial_tarfile}
fi

#------------------------------------------------------------------------------
#   4.4 PRE - PROCESSING : Computing environment
#------------------------------------------------------------------------------

# create and go to the temporary working directory

if [ "${work}" = "" ]; then
  echo "\n |- ERROR: Can't create the temporary working directory"
  echo " |     Variable 'work' is empty"
  exit
fi
cd ${work}
if [ ! -d ${expid} ]; then
  ${mkdir} ${expid}
fi
if [ ! -d ${expid}/work ]; then
  ${mkdir} ${expid}/work
fi
cd ${expid}/work
rm -rf *

echo "\n |- Temporary working directory is:\t$(pwd)"
echo " |- Data workshare on compute node is:\t$data/$expid"
#------------------------------------------------------------------------------
#     4.5 PRE - PROCESSING : Provide the executables
#------------------------------------------------------------------------------

oceexec=${ocemod}_${ocevers}.${message_passing}.x
atmexec=${atmmod}_${atmvers}.${message_passing}.x
cplexec=${coupler}.${message_passing}.x

#
# remove old executables to get them anew from the compiling host 
#
if [ ${jobnum} = 1 ]; then
  [ ! -f ${bindir}/${oceexec} ]     || rm    ${bindir}/${oceexec}
  [ ! -f ${bindir}/${atmexec} ]     || rm    ${bindir}/${atmexec}
  [ ! -f ${bindir}/${cplexec} ]     || rm    ${bindir}/${cplexec}
fi

get_file   ${ocemod}   bin   ${oceexec}       mpi-om
for aid in ${atmids} ; do
  modname=${atmmonprefix}${aid}
  get_file   ${atmmod}   bin   ${atmexec}    ${modname}
done
get_file   ${coupler}  bin   ${cplexec}       oasis.x

#------------------------------------------------------------------------------
#     4.6 PRE - PROCESSING : Provide the input data 
#------------------------------------------------------------------------------

echo " |- Get input and restart data\n"

#------------------------------------------------------------------------------
# Input files for the coupler (OASIS3)
#-------------------------------------

# List of variable names according to cf conventions 
#
get_file   ${coupler}  input   cf_name_table.txt

# Grid and analysis auxiliary data files
#

FV_cpl=_frac

if [ $gridswr = 0 ] || [ $jobnum != 1 ]; then
  get_file -opt  ${coupler}  input  grids_${res_atm}_${res_oce}${FV_cpl}.nc \
                                    grids.nc
  get_file -opt  ${coupler}  input  areas_${res_atm}_${res_oce}${FV_cpl}.nc \
                                    areas.nc
  get_file -opt  ${coupler}  input  masks_${res_atm}_${res_oce}${FV_cpl}.nc \
                                    masks.nc
fi

if [ $scripwr = 0 ] || [ $jobnum != 1 ]; then
  get_file -opt ${coupler} input  \
              rmp_oces_to_atmo_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc \
              rmp_oces_to_atmo_CONSERV_FRACAREA.nc
  get_file -opt ${coupler} input  \
              rmp_atmo_to_oces_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc \
              rmp_atmo_to_oces_CONSERV_FRACAREA.nc
  get_file -opt ${coupler} input  \
              rmp_atmo_to_oceu_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc \
              rmp_atmo_to_oceu_CONSERV_FRACAREA.nc
  get_file -opt ${coupler} input  \
              rmp_atmo_to_ocev_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc \
              rmp_atmo_to_ocev_CONSERV_FRACAREA.nc
  get_file -opt ${coupler} input  \
              rmp_atmo_to_oces_BILINEA_${res_atm}_${res_oce}.nc \
              rmp_atmo_to_oces_BILINEA.nc
fi

if [ $extrapwr = 0 ] || [ $jobnum != 1 ]; then
  get_file ${coupler} input nweights_${res_atm}_${res_oce}${FV_cpl} nweights
fi

# Restart files
# -------------
for aid in ${atmids} ; do # for multi models
prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
if [ ${jobnum} = 1 ]; then
  if [ ${cpl_restart} = 1 ]; then
    if [ ${run_mode} = concurrent ]; then
		  cdo chname,TXWATMOU,TXWA${aid}OU,TXWATMOV,TXWA${aid}OV,TYWATMOU,TYWA${aid}OU,TYWATMOV,TYWA${aid}OV,TXIATMOU,TXIA${aid}OU,TXIATMOV,TXIA${aid}OV,TYIATMOU,TYIA${aid}OU,TYIATMOV,TYIA${aid}OV,FRIATMOS,FRIATA${aid},FRWATMOS,FRWATA${aid},RHIATMOS,RHIATA${aid},CHIATMOS,CHIATA${aid},NHWATMOS,NHWATA${aid},SHWATMOS,SHWATA${aid},WSVATMOS,WSVATA${aid} ${restdir}/oasis3/flxatmos.nc flxatm${aid}
      #\cp  ${cpl_restart_file_flxatmos}  flxatmos
    fi
    cdo chname,SSTOCEAN,SSTOCE${aid},SITOCEAN,SITOCE${aid},SICOCEAN,SICOCE${aid},SNTOCEAN,SNTOCE${aid},OCUOCEAN,OCUOCE${aid},OCVOCEAN,OCVOCE${aid} ${restdir}/oasis3/sstocean.nc sstoce${aid}
    #\cp  ${cpl_restart_file_sstocean}  sstocean
  fi
else
  if [ ${run_mode} = concurrent ]; then
    get_file ${coupler} restart flxatm${aid}_${expid}_${prevdate}.nc   flxatm${aid}
  fi
  get_file ${coupler} restart sstoce${aid}_${expid}_${prevdate}.nc   sstoce${aid}
fi
done # for multi models
#------------------------------------------------------------------------------
# Input files for the atmosphere (ECHAM5)
#----------------------------------------

#
#-- Initialization and forcing
#   --------------------------
#
# 3d initial file of atmosphere (spectral, no dependence on lsmask)
#
get_file ${atmmod} input ${res_atm}L${vres_atm}_jan_spec.nc     unit.23

#
# surface boundary conditions (land/sea mask, albedo etc.)
#   (the original file has been modified near Antarctica (M.Esch);
#    annual mean data); file depends on lsmask
#
get_file ${atmmod} input ${res_atm}${res_oce}_jan_surf.nc  unit.24

#
# AMIP sst and sea ice concentration; files depend on lsmask
#
if [ "${ocemod}" = "" ] && [ ${forcing} = amip ]; then
  typeset -Z4 yr yp1 ym1
  yr=`format_date -f4 -- ${startdate} | cut -f1 -d" "`
  (( yp1 = yr + 1 ))
  (( ym1 = yr - 1 ))
  for yrs in ${yr} ${yp1} ${ym1}; do
    get_file ${atmmod} input  ${res_atm}_amip2sst_${yrs}.nc  sst${yrs}
    get_file ${atmmod} input  ${res_atm}_amip2sic_${yrs}.nc  ice${yrs}
  done
else
  get_file ${atmmod} input ${res_atm}_amip2sst_clim.nc       unit.20
  get_file ${atmmod} input ${res_atm}_amip2sic_clim.nc       unit.96
fi

#
# ozone climatology (m.m., zonal) (no dependence on lsmask)
#
get_file ${atmmod} input ${res_atm}_O3clim2.nc             unit.21

yr0=$(echo ${startdate} | cut -c1-4)
(( yp1 = yr0 + 1 )); (( ym1 = yr0 - 1 )); (( ym2 = yr0 - 2 ))
if [[ ${yr0} -lt 1000 ]]; then
  yr0=0${yr0}
fi
if [[ ${yp1} -lt 1000 ]]; then
  yp1=0${yp1}
fi
if [[ ${ym1} -lt 1000 ]]; then
  ym1=0${ym1}
fi
if [[ ${ym2} -lt 1000 ]]; then
  ym2=0${ym2}
fi


get_file ${atmmod} input noaao3.1970_1979_ipccT31.nc ozon${ym2};
get_file ${atmmod} input noaao3.1970_1979_ipccT31.nc ozon${ym1};
get_file ${atmmod} input noaao3.1970_1979_ipccT31.nc ozon${yr0};
get_file ${atmmod} input noaao3.1970_1979_ipccT31.nc ozon${yp1}


#
# leaf area index climatology (monthly)
#
get_file ${atmmod} input ${res_atm}${res_oce}_VLTCLIM.nc   unit.90

#
#  3d vegetation climatology (a.m.) (monthly)
#
get_file ${atmmod} input ${res_atm}${res_oce}_VGRATCLIM.nc unit.91

#
#  land surface temperature climatology (monthly)
#
get_file ${atmmod} input ${res_atm}_TSLCLIM2.nc             unit.92

#
#  input data for radiation scheme
#
get_file ${atmmod} input surrta_data                    rrtadata

#
#  input data for the hydrological discharge model
#
if [ $lhd = yes ]; then
  get_file ${atmmod} input  hdpara.nc                   hdpara.nc
  get_file ${atmmod} input  hdstart.nc                  hdstart.nc
fi

#
#  input data for volcanic forcing
#
if [ ${volc_forc} = "true" ]; then
#  get_file ${atmmod} input volc_data                   volc_data
#  get_file ${atmmod} input rad_table                   rad_table
   cp ${jobdir}/volc_data                               volc_data
   cp ${jobdir}/rad_table                               rad_table
fi

#
#-- Restart files
#   -------------

for aid in ${atmids} ; do # for multi models
atmexpid=${expid}${aid}
if [ ${jobnum} != 1 ]; then
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${atmmod}  restart  rerun_${atmexpid}_echam_${prevdate} \
                               rerun_${atmexpid}_echam
  if [ $lhd = yes ]; then
    get_file ${atmmod} restart ${atmexpid}_hdrestart_${prevdate}.nc \
                               ${atmexpid}_hdrestart.nc
  fi
  if [ "${save_dblrad}" = "true" ]; then
    get_file ${atmmod}  restart  rerun_${atmexpid}_accuflx_${prevdate} \
                                 rerun_${atmexpid}_accuflx
  fi 
  if [ "${srfmod}" = "jsbach" ]; then
    get_file ${atmmod} restart  rerun_${atmexpid}_co2_${prevdate} \
                                rerun_${atmexpid}_co2
  fi
  if [ "${co2_transport}" = "true" ]; then
    get_file ${atmmod} restart  rerun_${atmexpid}_tracer_${prevdate} \
                                rerun_${atmexpid}_tracer
  fi
elif [ ${atm_restart} = 1 ] ; then
  \cp ${atm_restart_file}    rerun_${atmexpid}_echam
  if [ "${srfmod}" = "jsbach" ]; then
    \cp ${atm_restart_co2}     rerun_${atmexpid}_co2
  fi
  if [ $lhd = yes ]; then
    \cp ${hd_restart_file}   ${atmexpid}_hdrestart.nc
  fi
  if [ "${co2_transport}" = "true" ]; then
    \cp ${atm_restart_tracer}  rerun_${atmexpid}_tracer
  fi
  if [ "${save_dblrad}" = "true" ]; then
    \cp ${atm_restart_accu}  rerun_${atmexpid}_accuflx
  fi
fi
done  # for the multi model 
#------------------------------------------------------------------------------
# Input files for the ocean (MPIOM)
#----------------------------------

#
#-- Initialization and forcing
#   --------------------------
#
# File containing basin masks (formatted)
#
get_file ${ocemod} input ${res_oce}_BEK               BEK
chmod ${dir_permits} BEK



#
# Ocean grid and bathymetry file
#
get_file ${ocemod} input ${res_oce}_anta              anta
get_file ${ocemod} input ${res_oce}_arcgri            arcgri
get_file ${ocemod} input ${res_oce}_topo_jj           topo

#
# Surface salinity file (a.m. Levitus atlas).
#
get_file ${ocemod} input ${res_oce}L${vres_oce}_SURSAL_PHC  SURSAL

#
#  Initial (3D) ocean temperature/salinity file (Levitus a.m.).
#
get_file ${ocemod} input ${res_oce}L${vres_oce}_INITEM_PHC  INITEM
get_file ${ocemod} input ${res_oce}L${vres_oce}_INISAL_PHC  INISAL

#
#-- Forcing (for stand allone ocean runs)
#   -------

if [  "${message_passing}" = "NONE" ]; then
  get_file ${ocemod} input  ${res_oce}_GICLOUD_OMIP365     GICLOUD
  get_file ${ocemod} input  ${res_oce}_GIPREC_OMIP365      GIPREC
  get_file ${ocemod} input  ${res_oce}_GISWRAD_OMIP365     GISWRAD
  get_file ${ocemod} input  ${res_oce}_GITDEW_OMIP365      GITDEW
  get_file ${ocemod} input  ${res_oce}_GITEM_OMIP365       GITEM
  get_file ${ocemod} input  ${res_oce}_GIU10_OMIP365       GIU10
  get_file ${ocemod} input  ${res_oce}_GIWIX_OMIP365       GIWIX
  get_file ${ocemod} input  ${res_oce}_GIWIY_OMIP365       GIWIY
  get_file ${ocemod} input  ${res_oce}_GIRIV_OMIP365       GIRIV
fi

#
#-- Restart files
#   -------------

if [ ${jobnum} = 1 ]; then
  if [ ${oce_restart} = 1 ] ; then
    \cp ${oce_restart_file}         Z38000
    \cp ${oce_restart_file}         Z37000
  fi
else
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${ocemod} restart RESTART_${expid}_${prevdate}  Z38000
  get_file ${ocemod} restart RESTART_${expid}_${prevdate}  Z37000
fi

#------------------------------------------------------------------------------
#     4.7 PRE - PROCESSING : 
#                 Provide and update configuration files (namelists, XML, etc.)
#------------------------------------------------------------------------------

echo "\n |- Provide configuration files (namelists, XML, etc.)"
#------------------------------------------------------------------------------
#-- Namelist OASIS3 (namcouple)
#

#
# runtime: duration of the experiment (seconds)
#
runtime=`time_between -c${caltype} -- ${startdate} ${nextdate} seconds`

#
# startdate in format YYYYMMDD
#
#typeset -Z8 yyyymmdd
yyyymmdd=`echo ${startdate#-} | cut -c1-8` 

#
# sequential mode and time lag
#

# both models run seqentially when the experiment is started
if [ ${jobnum} = 1 ] && [ ${cpl_restart} = 0 ]; then
  run_mode=sequential
fi

if [ ${run_mode} = sequential ]; then
  nmseq=2                         # models run sequentially
  lago2a=$nodt
  laga2o=`expr $nadt - $dta2o`
  iseq=2
else
  nmseq=1                         # models run concurrently
  iseq=1
  lago2a=$nodt
  laga2o=$nadt
fi

#
# buffered/simple MPI send
#
if [ ${bsend} = no ]; then
  nobsend="NOBSEND"
else
  nobsend=""
fi

#
# restart filenames for the atmosphere/ocean
#
cnfileaw=flxatm
cnfileow=sstoce
#cnfileaw=flxatmos
#cnfileow=sstocean

#
# loctrans
#
loctrans=LOCTRANS

#
# adaption of the namcouple template
#
get_file -nolink  ${coupler}  input  namcouple_${cplmod}${ncplvers}   namcouple

[[ $monitoring = yes ]] && monexp="EXPOUT" || monexp="$export"

for aid in ${atmids} ; do
  modname=${atmmonprefix}${aid}
  atmmodsname="${atmmodsname}  "${modname}
done



ed -s namcouple <<EOF
g/#Nmseq/s/#Nmseq/${nmseq}/
g/#Chan/s/#Chan/${message_passing} ${nobsend}/
g/#Mod1procs/s/#Mod1procs/ ${nprocatm} ${ncplprocatm} $arg1 /
g/#Mod2procs/s/#Mod2procs/ ${nprococe} ${ncplprococe} $arg2 /
g/#Cplexptid/s/#Cplexptid/${jobname}/
g/#Atmmodnam/s/#Atmmodnam/${atmmodsname}/
g/#Ocemodnam/s/#Ocemodnam/mpi-om/
g/#Runtime/s/#Runtime/${runtime}/
g/#Yyyymmdd/s/#Yyyymmdd/${yyyymmdd}/
g/#Nlogprt/s/#Nlogprt/${nlogprt}/
g/#Dta2o/s/#Dta2o/${dta2o}/
g/#Dto2a/s/#Dto2a/${dto2a}/
g/#Iseq/s/#Iseq/${iseq}/
g/#Laga2o/s/#Laga2o/${laga2o}/
g/#Lago2a/s/#Lago2a/${lago2a}/
g/#TimTransa2o/s/#TimTransa2o/${timtransa2o}/
g/#TimTranso2a/s/#TimTranso2a/${timtranso2a}/
g/#Exp/s/#Exp/${export}/
g/#Mon/s/#Mon/${monexp}/
g/#LocTrans/s/#LocTrans/${loctrans}/
g/#Extrapwr/s/#Extrapwr/${extrapwr}/
w
q
EOF

for aid in ${atmids} ; do # for multi models
  ed -s namcouple <<EOF3
g/#Cnfileaw${aid}/s/#Cnfileaw${aid}/${cnfileaw}${aid}/
g/#Cnfileow${aid}/s/#Cnfileow${aid}/${cnfileow}${aid}/
w
q
EOF3
done

echo "* ----------------------------------------------------------------------"
echo "* Namelist of OASIS3: namcouple"
echo "* ----------------------------------------------------------------------"
cat namcouple
echo "* ----------------------------------------------------------------------"
echo "*    end of namcouple"
echo "* ----------------------------------------------------------------------"
echo ""

#------------------------------------------------------------------------------
#-- Namelist ECHAM5
#

#
# resumed or initial run?
#
if [ ${jobnum} = 1 ] && [ ${atm_restart} = 0 ]; then
  rerun=.FALSE.
else
  rerun=.TRUE.
fi

#
# coupled or stand-alone run?
#
if [ "${ocemod}" = "" ]; then

# stand alone echam5

  lcouple=".FALSE."
  if [ ${forcing} = amip ]; then
    lamip=".TRUE."
  else
    lamip=".FALSE."
  fi
else

# echam5 coupled to ocean

  lcouple=".TRUE."
  lamip=".FALSE."
  getoff=0
  putoff=-$nadt
  na2ocsteps=`expr $dta2o / $nadt `
  no2acsteps=`expr $dto2a / $nadt `
  getocean="$no2acsteps,'steps','exact',$getoff"
  putocean="$na2ocsteps,'steps','exact',$putoff"
fi

#
# initial date of the experiment (with coupled runs: one timestep before
#    midnight)
# Initialisation of the echam time manager can take a long time if the current
# date is far from the initial date of the experiment. To improve this, we set
# the year in dt_start just one year befor the the current date.
# (Setting dt_start to the current date would lead to echam re-initialization!)
#    Note that events that do not occur on a yearly basis will not be treated
#    correctly!

if [ ${lcouple} = ".FALSE." ]; then
  date=`calc_date minus -c${caltype} -Y${atm_age} -- ${inidate}`
  year=`format_date -f4 -- ${inidate} | cut -f1 -d" "`
else
  date=`calc_date minus -c${caltype} -Y${atm_age} -s${nadt} -- ${inidate}`
  year=`format_date -f4 -- ${startdate} | cut -f1 -d" "`
  if (( ${year} < 999 )); then
    year=`echo ${year} | cut -c2-4`
  fi
#	(( Ryear = year + 1148 ))
  Ryear=${year}
  if [ ${rerun} = .TRUE. ]; then
    (( year = year - 2 ))
  fi
  if [ ${rerun} = .FALSE. ]; then
    (( year = year - 1 ))
  fi
  if (( ${year} < 999 )); then
    year=0${year}
  fi
fi
## year = 799
echo ${year}
echo ${Ryear}

#exit

month_day_time=`format_date -f4 -s -- ${date} | cut -f2- -d" "`
date="${year} ${month_day_time}"
dt_start=`echo ${date} | tr " " ,`

#
#  SST restoring
#

if [ ${IsRestoringSST} = 'yes' ]; then
  if [ ${nyear} = '1' ]; then
	  get_file -nolink ${ocemod} input ${inpdir}/${ocemod}/SST_forcing/skt.sfc.gauss.${Ryear}.GR30s.ext8     GISST
	elif [ ${nmonth} = '1' ]; then
	  month=`echo ${startdate} |  cut -c5-6`
    #get_file -nolink ${ocemod} input ${inpdir}/${ocemod}/SST_forcing/skt.sfc.gauss.${Ryear}.${month}.GR30s.ext8     GISST
    get_file -nolink ${ocemod} input ${inpdir}/${ocemod}/SST_forcing/skt.sfc.gauss.${Ryear}.GR30s.ext8   tmpGISST
		cdo selmon,${month} tmpGISST GISST
  fi
fi

#nyear=0          # number of years per run
#nmonth=1         # number of months per run

if [ ${UsingAreaWeight} = '.TRUE.' ]; then
  get_file -nolink   ${ocemod} input AlphaMap.ext8 WeightingMap
fi



#
# end date of the run
#
dt_stop=`format_date -f4 -s -- ${nextdate} | tr " " ,`

#
# rerun interval
#
if [ ${nmonth} -ne 0 ]; then
  (( nm = 12 * nyear + nmonth )) 
  put_rerun="${nm},'months','last',0"
elif [ ${nyear} -ne 0 ]; then
  put_rerun="${nyear},'years','last',0" 
elif [ ${nday} -ne 0 ]; then
  put_rerun="${nday},'days','last',0"
fi

#
# usage of the hydrology model (HD)
#
if [ ${lhd} = yes ]; then
  hd=.TRUE.
else
  hd=.FALSE.
fi

# 
# output data format
#
if [ ${out_filetype} = GRIB ]; then
  format=1
else
  format=2
fi

#
# usage of 1/0 sea land mask (not 0.5 criteria of fractional mask)
#
if [[ ${res_atm}  = T31  && (  ${alone_as_coupled} = true \
    || ${cplmod} = cosmos-aso || ${cplmod} = cosmos-asob ) ]]; then
  lslm=.true.
else
  lslm=.false.
fi

#
# CO2
#
if [ "${co2_transport}" = "true" ] && [ "${srfmod}" = "jsbach" ]; then
  ico2=1   # prognostic CO2 mass mixing ratio
else
  ico2=2   # uniform CO2 volume mixing ratio
fi

#
# Middle atmosphere
#
if [[ ${vres_atm} = 47 ]]; then
  middle_atmosphere=true
fi

nm=0
for aid in ${atmids} ; do # for multi models
atmexpid=${expid}${aid}
(( nm = nm + 1 ))

echo "&RUNCTL"                               >  namelist.echam
echo "  LRESUME   = ${rerun}"               >>  namelist.echam
echo "  out_datapath = './'"                >>  namelist.echam
echo "  out_expname  = '${atmexpid}'"          >>  namelist.echam
echo "  out_filetype = ${format}"           >>  namelist.echam
echo "  DT_START  = ${dt_start}"            >>  namelist.echam
echo "  DT_STOP   = ${dt_stop}"             >>  namelist.echam
if [[ ${nadt} != default ]]; then
  echo "  DELTA_TIME= ${nadt}."               >>  namelist.echam
fi
echo "  PUTDATA   = ${dt_write_atm},'hours','first',0" >>  namelist.echam
echo "  PUTRERUN  = ${put_rerun}"           >>  namelist.echam
echo "  TRIGFILES = 1,'months','first',0"   >>  namelist.echam
echo "  LAMIP     = ${lamip}"               >>  namelist.echam
echo "  LABORT    = .FALSE."                >>  namelist.echam
echo "  NPROCA    = ${nproca_atm}"          >>  namelist.echam
echo "  NPROCB    = ${nprocb_atm}"          >>  namelist.echam
echo "  NPROMA    = ${nproma_atm}"          >>  namelist.echam
echo "  LDEBUGEV  = .FALSE."                >>  namelist.echam
echo "  LCOUPLE   = ${lcouple}"             >>  namelist.echam
echo "  NO_CYCLES  = 1"                     >>  namelist.echam
echo "  LSO4      = .FALSE."                >>  namelist.echam
echo "  LHD       = ${hd}"                  >>  namelist.echam
if [ "${srfmod}" = "jsbach" ]; then
  echo "  LSLM      = ${lslm}"              >>  namelist.echam
fi

if [ "${co2_transport}" = "true" ] && [ "${srfmod}" = "jsbach" ]; then
  echo "  LCO2      = .TRUE."               >>  namelist.echam
fi

if [ ${volc_forc} = "true" ]; then
  echo "  L_VOLC    = .TRUE."               >>  namelist.echam
fi

if [ ${lhd} = yes ]; then
  echo "  NHD_DIAG  = 1"                    >>  namelist.echam
fi
if [ ${lcouple} = ".TRUE." ]; then
  echo "  GETOCEAN  = ${getocean}"          >>  namelist.echam
  echo "  PUTOCEAN  = ${putocean}"          >>  namelist.echam
fi
if [[ ${alone_as_coupled} = true ]]; then
  echo "  LIPCC = .TRUE."                   >>  namelist.echam
fi
if [[ ${middle_atmosphere} = true ]]; then
  echo "  LMIDATM = .TRUE."                 >> namelist.echam
fi
echo "/"                                    >>  namelist.echam

echo "&RADCTL"                              >>  namelist.echam
if [ ${lcouple} = .TRUE. ] && [ ${res_atm} = T31 ]; then
  echo "  TRIGRAD  = 120,'minutes','first',2400" >>  namelist.echam
fi
echo "  ICO2      = ${ico2}"                >>  namelist.echam

#------------------------------------------------------------------------------
  echo "  IO3=4"                           >>  namelist.echam
  echo "  IGHG=0"                           >>  namelist.echam
  echo "  IAERO=4"                          >>  namelist.echam
  echo "  ICFC=2"                           >>  namelist.echam
  echo "  ICH4=2"                           >>  namelist.echam
  echo "  IN2O=2"                           >>  namelist.echam
  echo "  ICO2=2 "                >>  namelist.echam

  echo "  CO2VMR=320.8875E-06"              >>  namelist.echam
  echo "  CH4VMR=1306.125E-09"              >>  namelist.echam
  echo "  N2OVMR=293.26875E-09"             >>  namelist.echam

if [ ${save_dblrad} = "true" ]; then
  echo "  LDBLRAD   = .TRUE."               >>  namelist.echam
fi
if [[ ${middle_atmosphere} = true ]]; then
  echo "  ICH4=3"                           >>  namelist.echam
  echo "  IN2O=3"                           >>  namelist.echam
fi
echo "/"                                    >>  namelist.echam

if [[ ${middle_atmosphere} = true ]]; then
  echo "&DYNCTL"                            >>  namelist.echam
  echo "  VCHECK=235."                      >>  namelist.echam
  echo "  SPDRAG=0.926E-4"                  >>  namelist.echam
  echo "/"                                  >>  namelist.echam
fi

if [[ ${lcouple} = .TRUE. || ${alone_as_coupled} = true ]]; then
echo "&PHYSCTL"                             >>  namelist.echam
echo "  LCOVER = .FALSE."                   >>  namelist.echam 
echo "  ICONV =  ${nm}"                          >>  namelist.echam
echo "/"                                    >>  namelist.echam
fi
#--- Set output stream properties:
#
echo "&SET_STREAM_ELEMENT   name = 'az0l'    lpost  = 0   /" >>  namelist.echam
echo "&SET_STREAM_ELEMENT   name = 'slm'     lpost  = 0   /" >>  namelist.echam
echo "&SET_STREAM_ELEMENT   name = 'glac'    lpost  = 0   /" >>  namelist.echam
echo "&SET_STREAM_ELEMENT   name = 'runtoc'  lpost  = 1   /" >>  namelist.echam
echo "&SET_STREAM_ELEMENT   name = 'ao3'     lpost  = 0   /" >>  namelist.echam

cp namelist.echam namelist.echam${aid}

echo "* ----------------------------------------------------------------------"
echo "* Namelist of ECHAM5: namelist.echam"
echo "* ----------------------------------------------------------------------"
cat namelist.echam${aid}
echo "* ----------------------------------------------------------------------"
echo "*    end of namelist.echam"
echo "* ----------------------------------------------------------------------"
echo ""
done # for the multi models
#------------------------------------------------------------------------------
#-- Namelist MPIOM
#

if [ ${vres_oce} = 20 ]; then
  dzw="20.,20.,20.,30.,40.,50.,70.,90.,120.,150.
      ,180.,210.,250.,300.,400.,500.,600.,700.,900.,1400."
elif [ ${vres_oce} = 23 ]; then
  dzw="20.,20.,25.,25.,25.,25.,25.,30.,45.,60.
      ,90.,120.,150.,180.,210.,250.,300.,400.,500.,600.
      ,700.,900.,1400."
elif [ ${vres_oce} = 40 ]; then
  dzw="12.,10.,10.,10.,10.,10.,13.,15.,20.,25.
      ,30.,35.,40.,45.,50.,55.,60.,70.,80.,90.
      ,100.,110.,120.,130.,140.,150.,170.,180.,190.,200.
      ,220.,250.,270.,300.,350.,400.,450.,500.,500.,600."
elif [ ${vres_oce} = ""]; then
   echo 'ERROR: '
   echo '  Vertical resolution of the ocean model not specified!'
   echo ''
else
   echo 'ERROR: '
   echo '  No layerdepth known for vres_oce = '  ${vres_oce}
   echo ''
fi

#
# to allow test runs with just a few days
#
if [ ${nmonth} = 0 ] && [ ${nyear} = 0 ]; then
  nmonts=1
else 
  (( nmonts = ${nyear} * 12 + ${nmonth} ))
fi

#
# mean output
#
imean=2

#
# relaxation time for salinity
#

if [ "$coupler" = "" ]; then
  crelsal=3.8E-8
  crelsal=3.E-7
else
  crelsal=0.0
fi

#
# restarted run or start from levius
#
if [ ${jobnum} != 1 ] || [ ${oce_restart} = 1 ]; then
  istart=3
else
  istart=2
fi

cat -> OCECTL << EOF
&OCEDIM
 IE_G=${nx_oce}
 JE_G=${ny_oce}
 KE=${vres_oce}
/
&NPROCS
 NPROCX=${nproca_oce}
 NPROCY=${nprocb_oce}
/
&OCECTL
 exptid  = "$expid"
 DT      = $nodt.
 CAULAPTS= 0.0000
 CAULAPUV= 0.0060
 AUS     = 0.
 CAH00   = 1000.
 IBOLK   = 500
 DV0     = 0.2E-2
 AV0     = 0.2E-2
 CWT     = 0.5E-3
 CWA     = 0.75E-3
 CSTABEPS= 0.03
 DBACK   = 1.05E-5
 ABACK   = 5.E-5
 CRELSAL = ${crelsal}
 CDVOCON = 0.1
 NMONTS  = ${nmonts}
 IMEAN   = ${imean}
 ISTART  = ${istart}
 I3DREST = 0
 IOASISFLUX = 0
 IMOCDIAG = 1
 LDIFFDIAG = .true.
 LFORCEDIAG = .false. 
 LCONVDIAG = .false.
 LGRIDINFO = .false.
 LHFLDIAG = .false.
 LGMDIAG = .true.
 ITSDIAG = 2
 LTSTRANSPOSE = .true.
/
&OCEDZW
 CDZW = ${dzw}
/
&multiA
 modFDgids = ${modFDgids}
 modFDEmethods = ${mFDEmethods}
 modcoefs = ${mcoefs}
 modFDcoefs = ${mFDcoefs}
 LmodWMcoefs = ${UsingAreaWeight}
/
EOF

if [ ${IsRestoringSST} = 'yes' ]; then
  cat >> OCECTL << EOF2
&RESTOR
 THRtime = ${Temperture_Restoring_Time}
/
EOF2
fi

echo "* ----------------------------------------------------------------------"
echo "* Namelist of MPIOM: OCECTL"
echo "* ----------------------------------------------------------------------"
cat OCECTL
echo "* ----------------------------------------------------------------------"
echo "*    end of OCECTL"
echo "* ----------------------------------------------------------------------"
echo ""

#------------------------------------------------------------------------------
#
#     5. LAUNCHING THE MODEL
#
#------------------------------------------------------------------------------

ls -al
date
set -ex
export LID="`date +%y%m%d_%H%M%S`"
# Create a test file. The date of output files will be compared to the date
# of this reference file to assure, that the output files are newer. 
# (script save_file)

echo "The date of the output files is compared to the date of this file" \
	  > reference_file


jobname_mod=${expid}_ao.${jobid}

module load mpt


#-------------------------------------------------------------------------------
# Runtime environment variables
#-------------------------------------------------------------------------------

export F_UFMTENDIAN=10,20
export MPI_BUFS_PER_PROC=256
export MPI_BUFS_PER_HOST=1024
export MPI_BUFFER_MAX=2048
export MPI_MEMMAP_OFF=1
export OMP_NUM_THREADS=1
export MPI_DSM_VERBOSE=1
export MPI_STATS=1
export MPI_STATS_FILE=stats_${expid}
#-------------------------------------------------------------------------------

echo `pwd`
echo " |-------------------------------|"
echo " |- \$(date) |"
echo " |- Launch the model ${cplmod}   |"
echo " |-------------------------------|\n"


if [ ${message_passing} = MPI1 ]; then

  outlogfile=${jobdir}/out_${expid}_log_$LID
  nm=0
  idstr=""
  atmCommStr=""
  for aid in ${atmids} ; do # for multi models
    n=0
    modname=${atmmonprefix}${aid}
    arg=" --nprefix ${atmmonprefix} --id ${aid}"
    atmCommStr=${atmCommStr}"-n ${nprocatm} ./${modname} ${arg} : "
    (( nm = nm + 1 ))
    idstr=${idstr}${aid}
  done
  arg=" --nmodel ${nm} --ids ${idstr}"
  #echo "./mpi-om  ${arg}" >> mpmd.lst



  aprun -n 1 ./oasis.x : ${atmCommStr} -n ${nprococe} ./mpi-om  ${arg}   >&${outlogfile}  || {
  ls -lta
  exit 1
}


#   time -p mpiexec_mpt -np 1 ./oasis.x : ${atmCommStr} -np ${nprococe} ./mpi-om  ${arg}   >&${outlogfile}  || {
#  ls -lta
#  exit 1
#  }
else
  echo Invalid message passing method specified !
  exit 1
fi

echo " |-------------------------------|"
echo " |- \$(date) |"
echo " |- Model integration completed  |"
echo " |-------------------------------|\n"

#-----------------------------------------------------------------------------
#exit 0
#-----------------------------------------------------------------------------
# Log files

#save_file ${coupler} log ${jobdir}/out_${expid}_log.$LID
mv ${outlogfile} ${logdir}  || echo "Output log is not ready yet!!"
#exit


#
#-- Generate profiling protocol
#

ls -lat

#exit



if [ -f  *.${ocemod} ]; then
  echo 'Profiling '${oceexec}' ...'
  ${cp} *.${ocemod} ${logdir}/${ocemod}.mon.out
  ${cp} *.${ocemod} mon.out
  prof ${ocemod}
fi

if [ -f  *.${atmmod} ]; then
  echo 'Profiling '${atmexec}' ...'
  ${cp} *.${atmmod} ${logdir}/${atmmod}.mon.out
  ${cp} *.${atmmod} mon.out
  prof ${atmmod}
fi

if [ -f  *.oasis.x ]; then
  echo 'Profiling '${cplexec}' ...'
  ${cp} *.oasis.x ${logdir}/oasis.mon.out
  ${cp} *.oasis.x mon.out
  prof oasis.x
fi
#------------------------------------------------------------------------------
#
#     6. POST - PROCESSING: Saving the output data
#
#------------------------------------------------------------------------------

prepare_saving

saving_error=no

#------------------------------------------------------------------------------
# Definition of some time variables
# ---------------------------------
# enddate:      last day of this run
# prevdate:     last day of the previous run 
# startyear:    year at the beginning of this run
# prevyear:     year at the last day of the previous run
# startdecade:  decade at the beginning of this run
# prevdecade:   decade at the last day of the previous run
# previd:       job-id of the previous run (from expid.log)
# prevstart:    beginning of the previous run (from expid.log)

enddate=$(calc_date minus -c${caltype} -D1 -- ${nextdate})
prevdate=$(calc_date minus -c${caltype} -D1 -- ${startdate})
startyear=$(format_date -f4 -- ${startdate} | cut -f1 -d" ")
prevyear=$(format_date -f4 -- ${prevdate} | cut -f1 -d" ")
startdecade=${startyear%?}
prevdecade=${prevyear%?}
loginfo=$(get_logpid -d ${startdate} -f ${jobdir}/${expid}.log)                
previd=${loginfo%[ ]*}
prevstart=${loginfo#*[ ]}

[ ${task} = "RUN" ] && cd ${work}/${expid}/work

#------------------------------------------------------------------------------
# Save files of the coupler (OASIS3)
#-------------------------------------
# Output data (EXPOUT)
echo "    |- Save output files of the coupler $coupler"
if [ ${export} = "EXPOUT" ] || [ ${monitoring} = "yes" ]; then
  expoutdate=$(format_date -f2 -s -- ${startdate})
  expoutfiles=$(ls *_out.${expoutdate}.nc)
  for file in ${expoutfiles}; do
    save_file ${coupler} output ${file} 
  done
fi

# Log files
save_file ${coupler} log cplout cplout_${startdate}_${enddate}
save_file ${coupler} log Oasis.prt Oasis_${startdate}_${enddate}.prt

# Restart files
# Restart files
for aid in ${atmids} ; do # for multi models
  save_file ${coupler} restart flxatm${aid} flxatm${aid}_${expid}_${enddate}.nc
  save_file ${coupler} restart sstoce${aid} sstoce${aid}_${expid}_${enddate}.nc
done # end of multi models set up

if [ ${jobnum} = 1 ]; then
  echo "    |- Save input files of the coupler $coupler"
  FV_cpl=_frac
  # Grid description files (if just created)
  if [ ${gridswr} = 1 ]; then
    save_file ${coupler} input grids.nc grids_${res_atm}_${res_oce}${FV_cpl}.nc
    save_file ${coupler} input areas.nc areas_${res_atm}_${res_oce}${FV_cpl}.nc
    save_file ${coupler} input masks.nc masks_${res_atm}_${res_oce}${FV_cpl}.nc
  fi

  # SCRIP remapping matrices (if just created)
  for aid in ${atmids} ; do # for multi models
	if [ ${scripwr} = 1 ]; then
    save_file ${coupler} input \
          rmp_oces_to_at${aid}_CONSERV_FRACAREA.nc \
          rmp_oces_to_at${aid}_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc
    ocetypes="oces oceu ocev"
    for type in $ocetypes;
    do
      save_file ${coupler} input \
          rmp_at${aid}_to_${type}_CONSERV_FRACAREA.nc \
          rmp_at${aid}_to_${type}_CONSERV_FRACAREA_${res_atm}_${res_oce}.nc
    done
    save_file ${coupler} input \
          rmp_at${aid}_to_oces_BILINEA.nc \
          rmp_at${aid}_to_oces_BILINEA_${res_atm}_${res_oce}.nc
  fi
	done # end of multi models set up

  # extrapolation matrix (if just created)
  if [ $extrapwr = 1 ]; then
    save_file ${coupler} input nweights nweights_${res_atm}_${res_oce}${FV_cpl}
  fi
fi
###############################################################################
#
#  Save raw output of ECHAM
#
###############################################################################
echo "\n+++++ Save ECHAM5 output from $work to $data"

# check output format and save code files for first run
if [ "${out_filetype}" = "NETCDF" ]; then
  suf0=.nc
  suff=.nc
  method=tar
elif [ "${out_filetype}" = "GRIB" ];then 
  suf0=""
  suff=.grb
  method=cat
else
  echo "    |- ERROR: Unsupported output file format ${out_filetype}\n"
  exit 0
fi

for aid in ${atmids} ; do # for multi models
expmod=${expid}${aid}_${atmmod}
datastreams="${expmod}"
[[ "${srfmod}" = "jsbach" ]] && datastreams="${datastreams} ${expmod}_co2"
[[ "${co2_transport}" = "true" ]] && datastreams="${datastreams} ${expmod}_tracer"
[[ "${save_dblrad}" = "true" ]] && datastreams="${datastreams} ${expmod}_accuflx"

# Save ECHAM raw output
echo "    |- Save ECHAM5 monthly raw (and restart) files of\n       datastreams $datastreams"
for datastream in ${datastreams};do
  if [[ "${datastream}" = "${expmod}" ]];then
    substream=""
    resubstr="_echam"
  else
    substream="_${datastream##*_}"
    resubstr="$substream"
  fi
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date -f4 -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    ym=${year}${month}
		save_file ${atmmod} output ${expid}${aid}_${ym}.01${substream}${suf0} ${datastream}_${ym}${suff} &
    date=$(calc_date plus -c${caltype} -M1 -- ${date})
  done # months

  # Save ECHAM code files (for the first run)
  if [ ${jobnum} = 1 ]; then
	  save_file ${atmmod} log ${expid}${aid}_${startyear}01.01${substream}.codes ${expid}_${atmmod}${substream}.codes
  fi

  # Save restart files
  save_file ${atmmod} restart rerun_${expid}${aid}${resubstr} rerun_${expid}${aid}${resubstr}_${enddate} &
done # datastreams
done # multi models


#if [ "${lhd}" = "yes" ]; then  # hd output is switched off!
#  save_file ${atmmod} output ${expid}_${year}01.01_hd_higres.nc ${expmod}_hd_higres_${startdate}.nc &
#fi     

# Save log files
for aid in ${atmids} ; do # for multi models
atmexpid=${expid}${aid}
if [ ${message_passing} != NONE ]; then
  modname=${atmmonprefix}${aid}
	save_file ${atmmod} log atmout${aid} atmout${aid}_${startdate}_${enddate}
	save_file ${atmmod} log ${modname}.prt0 ${modname=}_${startdate}_${enddate}.prt0
fi

# Save hydrology restart files
if [ $lhd = yes ]; then
  echo "   |- Save ECHAM5 hydrology restart files from $work in &data"
	save_file ${atmmod} restart ${atmexpid}_hdrestart.nc ${atmexpid}_hdrestart_${enddate}.nc ${atmexpid}_hdrestart_${prevdate}.nc
fi
done # for multi models

###############################################################################
#
#  Save output files of MPIOM
#
###############################################################################
echo "\n+++++ MPIOM output saving"
runper=${startdate}_${enddate}
### Rename and tar raw output fortran files

if [ -f fort.270 ]; then
  mv fort.270 ${expid}_oasisflux # fluxes
fi

[ "$imean" != "0" ] && mv fort.71 ${expid}_mpiom # main output

if [ -f fort.tar ]; then
  rm fort.tar
fi

# tarfile of all remaining fort.* and TIMESER.*
[ $(ls fort.* | wc -l) -ge 1 ] && tar cvf  fort.tar  fort.*

if [ -f TIMESER.asc ]; then
  cp TIMESER.asc TIMESER.${runper}.asc
  if [ -f fort.tar ]; then
    tar rvf fort.tar TIMESER.${runper}.asc
  else
    tar cvf fort.tar TIMESER.${runper}.asc
  fi
fi

if [ -f TIMESER.ext ]; then
  cp TIMESER.ext TIMESER.${runper}.ext
  if [ -f fort.tar ]; then
    tar rvf fort.tar TIMESER.${runper}.ext
  else
    tar cvf fort.tar TIMESER.${runper}.ext
  fi
fi

### save raw output from compute node on workshare
outmod=${exphome}/outdata/${ocemod}
outfile=${expid}_${ocemod}
outfile_tp="${expid}_${ocemod}_${runper}"
if [ "$imean" != "0" ]; then
   save_file ${ocemod} output ${outfile} ${outfile_tp}.ext &
fi

### save oasisflux from compute node on workshare
outfile=${expid}_oasisflux
outfile_tp="${expid}_oasisflux_${runper}"
if [ -f ${outfile} ]; then
  save_file ${ocemod} output ${outfile} ${outfile_tp}.ext
fi

if [ -f fort.tar ] || [ -f ${outmod}/fort_${runper}.tar ] ; then
  save_file ${ocemod} output fort.tar fort_${runper}.tar
fi

# save TIMESER* to "data" directory but not individually to  archive since they are allready included in fort.tar
echo "    |- Save timeseries"
if [ -f TIMESER.asc ] ||  [ -f ${outmod}/TIMESER.${runper}.asc ] ; then
  save_file ${ocemod}  output  TIMESER.asc TIMESER.${runper}.asc
fi
if [ -f TIMESER.ext ] ||  [ -f ${outmod}/TIMESER.${runper}.ext ] ; then
  save_file ${ocemod}  output  TIMESER.ext TIMESER.${runper}.ext
fi

# Restart files
# find out, which of the restart files is the newest
file=$(ls -rt Z37000 Z38000 | tail -1)

# Log files
save_file ${ocemod} log oceout oceout_${runper}

if [ "${coupler}" = "oasis3" ]; then
   save_file ${ocemod} log  mpi-om.prt0 ${ocemod}_${runper}.prt0
fi

save_file ${ocemod} restart ${file} RESTART_${expid}_${enddate} &
#------------------------------------------------------------------------------
#
# Check whether everything was saved successfully
#
#------------------------------------------------------------------------------
wait

if [ ${saving_error} = no ]; then
  echo "    |+ Everything saved successfully"
  if [ -s rm.lst.$$ ] ; then
    echo "     |+ Removing files listed in file rm.lst.$$\n"
    for file in $(cat rm.lst.$$); do
      echo "      |- Removing file : $file\n"
      ${rm} $file
    done
    rm rm.lst.$$
  fi
  if [ "${rm_list}" != "" ]; then
    echo "     |- Removing files ${rm_list}\n"
    ${rm} ${rm_list}
  fi
else
  echo "      |- ERROR occured: saving_error = ${saving_error}\n"
fi
 
#------------------------------------------------------------------------------
#
#     8. SUBMISSION OF THE NEXT JOB
#
#------------------------------------------------------------------------------
cd  ${jobdir}

#
# Number of the next job
#

(( nextjob = ${jobnum} + 1 ))

#
# edit .date and .log file
#

space_error="no"

echo "${nextdate} ${nextjob}" > ${expid}.date.new || { 
  space_error="yes"; echo "Could not create ${expid}.date"; 
}
cp ${expid}.log ${expid}.log.new || { 
  space_error="yes"; echo "Could not save ${expid}.log"; 
}
echo "$(date +"${datefmt}") :  ${jobnum} ${nextdate} ${jobid}  - done" >> ${expid}.log.new || {
  space_error="yes"; echo "Could not append to ${expid}.log"; 
}

if [ "${space_error}" = "no" ]; then
  mv ${expid}.date.new ${expid}.date
  mv ${expid}.log.new ${expid}.log
else
  echo "No disk space left or quota exceeded?"
  echo " - Show quota"
  quota
  exit
fi

#
# Check whether final date is reached
#

#if [[ `later_date -- ${nextdate} ${findate}` = ${nextdate} ]]; then
#  echo "Experiment over"
#  echo "$(date +"${datefmt}") :  Experiment over" >> ${expid}.log
#else
#  qs=${queueing_system}
##  submit -q ${qs} ${job}
#	qsub ${job}
#fi

#------------------------------------------------------------------------------
#
#     9. EPILOGUE
#
#------------------------------------------------------------------------------


#
# Check whether final date is reached
#

if [[ `later_date -- ${nextdate} ${findate}` = ${nextdate} ]]; then
  echo "Experiment over"
  echo "$(date +"${datefmt}") :  Experiment over" >> ${expid}.log
else
  qs=${queueing_system}
#  submit -q ${qs} ${job}
  qsub ${job}
fi

cd ${jobdir}

if [ ${postprocessing} = yes ]; then

  cp ${expid}.post  ${expid}.post.${nextdate}
  ed -s ${expid}.post.${nextdate} <<EOF
1,100s/Jobnum/${jobnum}/
1,100s/Startdate/${startdate}/
1,100s/Nextdate/${nextdate}/
1,100s/Findate/${findate}/
w
q
EOF
  qs=${queueing_system_pp:-$queueing_system}
#  qsub -q ${qs} ${expid}.post.${nextdate}
  qsub ${expid}.post.${nextdate}
fi


date
${job_account}
wait
echo "\n This ${task} script ended                   at\t$(date | tr -s ' ' | cut -f2-4 -d' ') on host $(hostname)\n"
exit


